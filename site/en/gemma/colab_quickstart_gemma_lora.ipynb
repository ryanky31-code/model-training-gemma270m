{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ryanky31-code/model-training-gemma270m/blob/main/site/en/gemma/colab_quickstart_gemma_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cab02",
   "metadata": {},
   "source": [
    "# Gemma-3 270M LoRA / QLoRA Quickstart (Colab)\n",
    "\n",
    "This notebook helps you set up a Colab GPU runtime, install required packages, provide your Hugging Face token, choose a model variant, and run a small dry-run of the project's training CLI in `--mode lora` or `--mode qlora`.\n",
    "\n",
    "Open the runtime type as `GPU` before running the install cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d7329",
   "metadata": {},
   "source": [
    "## 1) Install dependencies (run in a GPU runtime)\n",
    "Run the cell below to install the core dependencies. For QLoRA you also need a compatible CUDA + bitsandbytes build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies. This may take a few minutes in Colab.\n",
    "!pip install --upgrade pip\n",
    "!pip install transformers accelerate datasets\n",
    "!pip install -r requirements-dev.txt\n",
    "# bitsandbytes and peft are optional but useful for LoRA/QLoRA runs; the pip may fail on some envs, so allow failure\n",
    "!pip install bitsandbytes peft || true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee94e0",
   "metadata": {},
   "source": [
    "## 2) Provide your Hugging Face token\n",
    "Run the cell and paste your HF token when prompted. The token is stored in the environment for the notebook session only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ced466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "token = getpass('Enter your Hugging Face token (input hidden): ')\n",
    "if token:\n",
    "  os.environ['HF_TOKEN'] = token\n",
    "  print('HF token set in environment for this session')\n",
    "else:\n",
    "  print('No token provided; some actions may be skipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad96a7",
   "metadata": {},
   "source": [
    "## 3) Choose model variant and mode\n",
    "Use the next cell to pick either `google/gemma-3-270m` (default) or another compatible Gemma checkpoint. Toggle QLoRA if you want to attempt 4-bit quantized flow (only if bitsandbytes is installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model id (change if you have a different HF checkpoint)\n",
    "model_id = 'google/gemma-3-270m'\n",
    "# Set to True to attempt QLoRA (requires bitsandbytes + CUDA)\n",
    "use_qlora = False\n",
    "# Example overrides: model_id = 'google/gemma-3-270m'\n",
    "print(f'Model: {model_id}, QLoRA enabled: {use_qlora}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f934a",
   "metadata": {},
   "source": [
    "## 4) Run smoke CSV generation and a small dry-run training check\n",
    "This will generate the smoke CSV and run the CLI in `--dry-run` mode. No actual training will be performed in dry-run mode.\n",
    "\n",
    "If you enabled QLoRA above and bitsandbytes is installed, the script will attempt to use QLoRA; otherwise it will fall back to LoRA or full-fine-tune scaffolding.\n",
    "\n",
    "Adjust `max_rows` to a small number (e.g., 20) for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate smoke CSV and run a dry-run training check\n",
    "!python scripts/generate_synthetic_smoke.py\n",
    "!python scripts/finetune_gemma_from_csv.py --csv synthetic_wifi_5ghz_outdoor_smoke.csv --mode lora --dry-run --max-rows 20 --target-field expected_throughput_mbps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266bb47",
   "metadata": {},
   "source": [
    "## 5) Next steps\n",
    "- If the dry-run shows dataset preparation and LoRA scaffolding, you can run a real LoRA training by removing `--dry-run` and setting small `--num-epochs` and `--per-device-batch-size`.\n",
    "- For QLoRA, make sure the bitsandbytes installation succeeded and your runtime has a compatible CUDA version."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
