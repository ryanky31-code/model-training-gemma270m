{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ryanky31-code/model-training-gemma270m/blob/main/site/en/gemma/docs/core/huggingface_text_full_finetune_with_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68a26b",
   "metadata": {
    "id": "0b68a26b"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ryanky31-code/model-training-gemma270m/blob/main/site/en/gemma/docs/core/huggingface_text_full_finetune_with_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e24bc",
   "metadata": {
    "id": "a71e24bc"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f276b3",
   "metadata": {
    "id": "52f276b3"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f96b0",
   "metadata": {
    "id": "c68f96b0"
   },
   "source": [
    "# Full Model Fine-Tune using Hugging Face Transformers (with embedded dataset generator)\n",
    "\n",
    "This notebook is based on the working example `huggingface_text_full_finetune.ipynb` but embeds a synthetic dataset generator and adapts the data-loading cells so you can run end-to-end in Colab or locally.\n",
    "\n",
    "Sections:\n",
    "- Install dependencies\n",
    "- Generate synthetic dataset (small default for smoke tests)\n",
    "- Save dataset and compute SHA256\n",
    "- Convert CSV → conversational dataset (train/test)\n",
    "- Load model & tokenizer\n",
    "- Configure SFT and train\n",
    "- Test inference\n",
    "\n",
    "Defaults are set to small values so you can test quickly; increase sample counts and epochs for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7690d429",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7690d429",
    "outputId": "ce9ba6b0-d627-455d-a432-ec141af2b2f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Downloading trl-0.22.2-py3-none-any.whl (544 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.22.2\n",
      "If running in Colab: enable the above pip install cell.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (Colab friendly)\n",
    "# Uncomment in Colab or run in your environment\n",
    "%pip install torch transformers datasets trl accelerate tensorboard sentencepiece protobuf pandas numpy\n",
    "\n",
    "print('If running in Colab: enable the above pip install cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c66d1",
   "metadata": {
    "id": "602c66d1"
   },
   "source": [
    "## 1) Imports and reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee06ca5d",
   "metadata": {
    "id": "ee06ca5d"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import zipfile\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reproducibility\n",
    "RSEED = 42\n",
    "random.seed(RSEED)\n",
    "np.random.seed(RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f5c77",
   "metadata": {
    "id": "bb8f5c77"
   },
   "source": [
    "## 2) Dataset generator (embedded)\n",
    "\n",
    "This is the user's generator adapted to run inside the notebook. Change `N_SAMPLES` for bigger sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbe1524",
   "metadata": {
    "id": "bbbe1524"
   },
   "outputs": [],
   "source": [
    "# Parameters (adjust for smoke tests or full runs)\n",
    "N_SAMPLES = 200  # small default for smoke tests; increase to 10000+ for real training\n",
    "OUT_DIR = '/content' if os.path.exists('/content') else '.'\n",
    "CSV_PATH = os.path.join(OUT_DIR, 'synthetic_wifi_5ghz_outdoor.csv')\n",
    "ZIP_PATH = os.path.join(OUT_DIR, 'synthetic_wifi_5ghz_outdoor.zip')\n",
    "\n",
    "# Constants\n",
    "FREQS_MHZ = list(range(4900, 6101, 5))\n",
    "ENVIRONMENTS = [\"Urban\", \"Rural\"]\n",
    "DENSITIES    = [\"Low\", \"Medium\", \"High\"]\n",
    "WEATHER_COND = [\"Clear\", \"Cloudy\", \"Rain\", \"Fog\", \"Snow\", \"Storm\"]\n",
    "OBST_TYPES   = [\"None\", \"Tree\", \"Building\", \"Vehicle\", \"Crane\", \"Billboard\"]\n",
    "TX_ANT_GAIN_DB = 15.0\n",
    "RX_ANT_GAIN_DB = 15.0\n",
    "BANDWIDTHS_MHZ = [20, 40, 80, 160]\n",
    "\n",
    "# Helper functions\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p = math.pi / 180.0\n",
    "    dlat = (lat2 - lat1) * p\n",
    "    dlon = (lon2 - lon1) * p\n",
    "    a = (math.sin(dlat / 2) ** 2 + math.cos(lat1 * p) * math.cos(lat2 * p) * math.sin(dlon / 2) ** 2)\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "def snr_to_efficiency_bps_per_hz(snr_db: float) -> float:\n",
    "    return 10.0 / (1.0 + math.exp(-(snr_db - 25.0) / 4.0))\n",
    "\n",
    "def fspl_db(distance_m: float, freq_mhz: float) -> float:\n",
    "    if distance_m < 1:\n",
    "        distance_m = 1.0\n",
    "    d_km = distance_m / 1000.0\n",
    "    return 32.45 + 20 * math.log10(d_km) + 20 * math.log10(freq_mhz)\n",
    "\n",
    "def weather_extra_loss_db(weather: str, distance_m: float) -> float:\n",
    "    d_km = distance_m / 1000.0\n",
    "    base = {\"Clear\": 0.0, \"Cloudy\": 0.2, \"Fog\": 0.6, \"Rain\": 0.8, \"Snow\": 0.9, \"Storm\": 1.5}[weather]\n",
    "    return base * d_km\n",
    "\n",
    "def density_obstruction_factor(env: str, density: str) -> float:\n",
    "    return {\"Urban\": {\"Low\": 0.5, \"Medium\": 1.5, \"High\": 3.0},\n",
    "            \"Rural\": {\"Low\": 0.1, \"Medium\": 0.4, \"High\": 0.8}}[env][density]\n",
    "\n",
    "def fresnel_penalty_db(f_clear: float) -> float:\n",
    "    if f_clear >= 90: return 0.0\n",
    "    if f_clear >= 70: return 1.0\n",
    "    if f_clear >= 50: return 3.0\n",
    "    if f_clear >= 30: return 6.0\n",
    "    return 10.0\n",
    "\n",
    "def obstruction_penalty_db(obstructed: bool, obst_type: str) -> float:\n",
    "    if not obstructed or obst_type == \"None\": return 0.0\n",
    "    return {\"Tree\": 3.0, \"Vehicle\": 2.0, \"Billboard\": 4.0, \"Building\": 8.0, \"Crane\": 5.0}.get(obst_type, 2.0)\n",
    "\n",
    "\n",
    "def generate_synthetic_row(scenario_id: int):\n",
    "    environment = random.choice(ENVIRONMENTS)\n",
    "    density = random.choice(DENSITIES)\n",
    "    lat_a = random.uniform(33.0, 36.0)\n",
    "    lon_a = random.uniform(35.0, 37.0)\n",
    "    el_a = random.uniform(5, 900)\n",
    "    lat_b = lat_a + random.uniform(-0.15, 0.15)\n",
    "    lon_b = lon_a + random.uniform(-0.15, 0.15)\n",
    "    el_b = random.uniform(5, 900)\n",
    "    distance_m = haversine_m(lat_a, lon_a, lat_b, lon_b)\n",
    "    weather = random.choice(WEATHER_COND)\n",
    "    humidity = random.uniform(20, 95)\n",
    "    temp_c = random.uniform(-5, 42)\n",
    "\n",
    "    f_range = {\"Urban\": {\"Low\": (60, 100), \"Medium\": (40, 90), \"High\": (15, 80)},\n",
    "               \"Rural\": {\"Low\": (85, 100), \"Medium\": (65, 100), \"High\": (45, 100)}}\n",
    "    fresnel_clear = random.uniform(*f_range[environment][density])\n",
    "\n",
    "    obstructed = random.random() < (0.65 if (environment == \"Urban\" and density == \"High\") else 0.35 if environment == \"Urban\" else 0.2 if density != \"Low\" else 0.1)\n",
    "    obst_type = random.choice(OBST_TYPES if obstructed else [\"None\"])\n",
    "\n",
    "    nf_range = {\"Urban\": {\"Low\": (-105, -92), \"Medium\": (-100, -88), \"High\": (-95, -82)},\n",
    "                \"Rural\": {\"Low\": (-115, -102), \"Medium\": (-110, -98), \"High\": (-108, -96)}}\n",
    "    noise_floor_dbm = random.uniform(*nf_range[environment][density])\n",
    "    noise_dbm = noise_floor_dbm + random.uniform(0, 8)\n",
    "\n",
    "    tx_power_dbm = random.uniform(10, 30)\n",
    "    channel_bw_mhz = random.choice(BANDWIDTHS_MHZ)\n",
    "    num_avail = random.randint(10, 50)\n",
    "    available_channels = sorted(random.sample(FREQS_MHZ, k=num_avail))\n",
    "\n",
    "    util_map = {(\"Urban\", \"Low\"): (20, 60), (\"Urban\", \"Medium\"): (40, 80), (\"Urban\", \"High\"): (60, 98),\n",
    "                (\"Rural\", \"Low\"): (0, 20), (\"Rural\", \"Medium\"): (10, 40), (\"Rural\", \"High\"): (20, 55)}\n",
    "    util_pct = random.uniform(*util_map[(environment, density)])\n",
    "    spectral_scan = {}\n",
    "    for ch in available_channels:\n",
    "        congestion_bump = np.random.normal(loc=util_pct / 100 * 8.0, scale=1.5)\n",
    "        spectral_scan[ch] = noise_floor_dbm + 2.0 + max(0.0, congestion_bump)\n",
    "\n",
    "    best = None\n",
    "    for ch in available_channels:\n",
    "        fspl = fspl_db(distance_m, ch)\n",
    "        loss = (weather_extra_loss_db(weather, distance_m)\n",
    "                + density_obstruction_factor(environment, density) * (distance_m / 1000.0)\n",
    "                + fresnel_penalty_db(fresnel_clear)\n",
    "                + obstruction_penalty_db(obstructed, obst_type))\n",
    "        rssi = (tx_power_dbm + TX_ANT_GAIN_DB + RX_ANT_GAIN_DB) - fspl - loss\n",
    "        interference_dbm = spectral_scan[ch]\n",
    "        snr = rssi - interference_dbm\n",
    "        score = snr - 0.25 * (interference_dbm - noise_floor_dbm)\n",
    "        if (best is None) or (score > best[3]):\n",
    "            best = (ch, rssi, snr, score)\n",
    "\n",
    "    ch_best, rssi_best, snr_best, _ = best\n",
    "    eff = snr_to_efficiency_bps_per_hz(max(-10.0, min(60.0, snr_best)))\n",
    "    expected_throughput_mbps = (eff * channel_bw_mhz * 1e6) / 1e6\n",
    "\n",
    "    return {\n",
    "        \"scenario_id\": scenario_id,\n",
    "        \"device_a_coordinates\": json.dumps([lat_a, lon_a, el_a]),\n",
    "        \"device_b_coordinates\": json.dumps([lat_b, lon_b, el_b]),\n",
    "        \"link_distance_m\": float(distance_m),\n",
    "        \"noise_dbm\": float(noise_dbm),\n",
    "        \"noise_floor_dbm\": float(noise_floor_dbm),\n",
    "        \"rssi_dbm\": float(rssi_best),\n",
    "        \"snr_db\": float(snr_best),\n",
    "        \"tx_power_dbm\": float(tx_power_dbm),\n",
    "        \"channel_bandwidth_mhz\": int(channel_bw_mhz),\n",
    "        \"channel_utilization_pct\": float(util_pct),\n",
    "        \"available_channels_mhz\": json.dumps(available_channels),\n",
    "        \"spectral_scan_dbm\": json.dumps(spectral_scan),\n",
    "        \"fresnel_clear_pct\": float(fresnel_clear),\n",
    "        \"weather_temp_c\": float(temp_c),\n",
    "        \"weather_humidity_pct\": float(humidity),\n",
    "        \"weather_condition\": weather,\n",
    "        \"image_obstruction_detected\": bool(obstructed),\n",
    "        \"image_obstruction_type\": obst_type,\n",
    "        \"environment_type\": environment,\n",
    "        \"area_density\": density,\n",
    "        \"recommended_channel_mhz\": int(ch_best),\n",
    "        \"expected_throughput_mbps\": float(expected_throughput_mbps),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c42627f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c42627f",
    "outputId": "0f76378f-4160-4025-e519-5447d6f6d939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 rows -> /content/synthetic_wifi_5ghz_outdoor.csv\n",
      "CSV SHA256: 97f3938eea466e66ce9a012d980cca68779dd358d63f0fdb142c359cb51f94cf\n",
      "ZIP SHA256: 742fcb5fdd3e888a1525981ef2e45a8b5a36798ef1628c071852fd9a2e07da02\n",
      "[{'scenario_id': 0, 'device_a_coordinates': '[35.224651499279496, 35.489783707606954, 129.8864460300038]', 'device_b_coordinates': '[35.105400052130946, 35.561984031007256, 493.103047704773]', 'link_distance_m': 14795.478534408972, 'noise_dbm': -91.97565727841881, 'noise_floor_dbm': -97.70381418179804, 'rssi_dbm': -100.25172879502935, 'snr_db': -5.209917546618669, 'tx_power_dbm': 24.02649947180472, 'channel_bandwidth_mhz': 160, 'channel_utilization_pct': 44.149041254675645, 'available_channels_mhz': '[4905, 5015, 5020, 5030, 5095, 5100, 5175, 5255, 5330, 5335, 5340, 5355, 5385, 5440, 5470, 5650, 5790, 5870, 5875, 5930, 5935, 5980, 6010, 6090]', 'spectral_scan_dbm': '{\"4905\": -91.42681965190714, \"5015\": -92.37928733318077, \"5020\": -91.20035807427294, \"5030\": -89.88734609681195, \"5095\": -92.52312094350899, \"5100\": -92.52309631684776, \"5175\": -89.80307165816289, \"5255\": -91.02073878769463, \"5330\": -92.87610246032641, \"5335\": -91.35805081604504, \"5340\": -92.86701742064268, \"5355\": -92.87048551177936, \"5385\": -91.80894747407494, \"5440\": -95.04181124841068, \"5470\": -94.75926763019353, \"5650\": -93.01532217528545, \"5790\": -93.69113756192561, \"5870\": -91.70051988253107, \"5875\": -93.53392699470581, \"5930\": -94.29034643342692, \"5935\": -89.97341772804165, \"5980\": -92.51055533215379, \"6010\": -92.0705985743921, \"6090\": -94.30901316074417}', 'fresnel_clear_pct': 68.74551899214413, 'weather_temp_c': -3.5995306864106937, 'weather_humidity_pct': 51.64413647639528, 'weather_condition': 'Snow', 'image_obstruction_detected': False, 'image_obstruction_type': 'None', 'environment_type': 'Urban', 'area_density': 'Low', 'recommended_channel_mhz': 5440, 'expected_throughput_mbps': 0.8392512547182491}, {'scenario_id': 1, 'device_a_coordinates': '[34.37827463901553, 35.24965232570642, 830.4543579652031]', 'device_b_coordinates': '[34.251914698439066, 35.18760581012855, 567.6326205475268]', 'link_distance_m': 15162.160543774226, 'noise_dbm': -75.34957846328896, 'noise_floor_dbm': -82.19212023141014, 'rssi_dbm': -149.28444252665184, 'snr_db': -71.62044723829166, 'tx_power_dbm': 27.329673335105394, 'channel_bandwidth_mhz': 160, 'channel_utilization_pct': 68.34537661087022, 'available_channels_mhz': '[4990, 5105, 5115, 5165, 5210, 5240, 5245, 5350, 5365, 5370, 5385, 5480, 5490, 5580, 5610, 5675, 5710, 5715, 5725, 5755, 5770, 5780, 5795, 5830, 5965, 6080, 6095]', 'spectral_scan_dbm': '{\"4990\": -75.5410641893283, \"5105\": -74.55810621797573, \"5115\": -76.45098046867398, \"5165\": -74.16094307502202, \"5210\": -75.62544813741873, \"5240\": -75.16203072723044, \"5245\": -75.62705002088462, \"5350\": -71.94607282577712, \"5365\": -74.74473593964743, \"5370\": -76.31105649597437, \"5385\": -73.49067273438574, \"5480\": -76.55575557749705, \"5490\": -74.41119471003339, \"5580\": -77.66399528836018, \"5610\": -76.71676917588817, \"5675\": -74.42919824873684, \"5710\": -73.61679023254742, \"5715\": -74.46743768075557, \"5725\": -74.89796252612288, \"5755\": -75.17614564592446, \"5770\": -76.94227308809167, \"5780\": -75.80425641513258, \"5795\": -75.4154482589802, \"5830\": -73.13880676321216, \"5965\": -74.20906266818784, \"6080\": -77.36905033558463, \"6095\": -74.23836414844834}', 'fresnel_clear_pct': 17.978584937618045, 'weather_temp_c': 28.1148763021014, 'weather_humidity_pct': 63.30141089425715, 'weather_condition': 'Rain', 'image_obstruction_detected': True, 'image_obstruction_type': 'Building', 'environment_type': 'Urban', 'area_density': 'High', 'recommended_channel_mhz': 5580, 'expected_throughput_mbps': 0.25349795056404145}]\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset and save\n",
    "rows = [generate_synthetic_row(i) for i in range(N_SAMPLES)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "with zipfile.ZipFile(ZIP_PATH, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    z.write(CSV_PATH, arcname=os.path.basename(CSV_PATH))\n",
    "\n",
    "def sha256_of(path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as f:\n",
    "        for b in iter(lambda: f.read(chunk), b''):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "print(f\"Saved {len(df):,} rows -> {CSV_PATH}\")\n",
    "print('CSV SHA256:', sha256_of(CSV_PATH))\n",
    "print('ZIP SHA256:', sha256_of(ZIP_PATH))\n",
    "\n",
    "# Show head\n",
    "from IPython.display import display\n",
    "print(df.head(2).to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c9f52",
   "metadata": {
    "id": "233c9f52"
   },
   "source": [
    "## 4) Convert CSV -> conversational dataset (train/test)\n",
    "\n",
    "We adapt the original notebook's dataset loading to read the CSV we just generated and convert each row to a message pair `{role: user, content: prompt}, {role: assistant, content: target}`. The default target is `recommended_channel_mhz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab0a057",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ab0a057",
    "outputId": "0b207f15-f17f-4329-94de-7c4989b283d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared. Train size: 180\n",
      "Test size: 20\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "TARGET_FIELD = 'recommended_channel_mhz'  # change to expected_throughput_mbps if desired\n",
    "\n",
    "# Build prompt and target\n",
    "\n",
    "def build_prompt_from_row(r):\n",
    "    return (f\"Scenario id: {r['scenario_id']}\\n\"\n",
    "            f\"Distance (m): {r['link_distance_m']:.1f}\\n\"\n",
    "            f\"Env: {r['environment_type']} (density={r['area_density']})\\n\"\n",
    "            f\"Fresnel clear %: {r['fresnel_clear_pct']:.1f}\\n\"\n",
    "            f\"Weather: {r['weather_condition']}, temp C: {r['weather_temp_c']:.1f}\\n\"\n",
    "            f\"Noise floor (dBm): {r['noise_floor_dbm']:.1f}, RSSI (dBm): {r['rssi_dbm']:.1f}\\n\"\n",
    "            f\"Channel BW (MHz): {int(r['channel_bandwidth_mhz'])}\\n\\n\"\n",
    "            \"Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\")\n",
    "\n",
    "def build_target_from_row(r):\n",
    "    return str(int(r[TARGET_FIELD])) if TARGET_FIELD == 'recommended_channel_mhz' else f\"{float(r[TARGET_FIELD]):.2f}\"\n",
    "\n",
    "# Convert to messages\n",
    "samples = []\n",
    "for _, row in df.iterrows():\n",
    "    prompt = build_prompt_from_row(row)\n",
    "    target = build_target_from_row(row)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": target}]\n",
    "    samples.append({\"messages\": messages})\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(samples))\n",
    "# train/test split\n",
    "if len(dataset) > 20:\n",
    "    dataset = dataset.train_test_split(test_size=0.1)\n",
    "else:\n",
    "    dataset = {'train': dataset}\n",
    "\n",
    "print('Dataset prepared. Train size:', len(dataset['train']))\n",
    "if 'test' in dataset:\n",
    "    print('Test size:', len(dataset['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df07e5",
   "metadata": {
    "id": "f8df07e5"
   },
   "source": [
    "## 5) (Optional) Mount Drive / Hugging Face login\n",
    "\n",
    "If you're running in Colab, mount your Google Drive to save checkpoints and/or store your HF token in Colab userdata. Otherwise set `hf_token` as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8112cc85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8112cc85",
    "outputId": "9d843e13-33ad-4d12-be29-76fc1d004365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "If running in Colab, mount drive and login to Hugging Face as needed.\n"
     ]
    }
   ],
   "source": [
    "# Colab-specific helpers (uncomment when using Colab)\n",
    "from google.colab import drive, userdata\n",
    "drive.mount('/content/drive')\n",
    "hf_token = userdata.get('HF_TOKEN')\n",
    "from huggingface_hub import login\n",
    "login(hf_token)\n",
    "\n",
    "print('If running in Colab, mount drive and login to Hugging Face as needed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d9667",
   "metadata": {
    "id": "aa9d9667"
   },
   "source": [
    "## 6) Load model & tokenizer (Gemma base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee008b45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376,
     "referenced_widgets": [
      "1a1a044d7c1446dc8cee53eea41088cc",
      "b79dd8f6d75a4d388046382fd15963d8",
      "6c7302b5ad4f4375930e80dc7be95037",
      "70846cba48514bcb9fbab5807ecb0962",
      "f856d0058db742908903a15d3dc9542f",
      "94ff2afccbef4dd2852eb03cfc915afc",
      "e5e01201ff2841fea4e511ca0e9f294f",
      "2052e4ae87264a29803fc25f26fb2bce",
      "1883197b22134aab9271822fb74b6440",
      "e7fbbdb84e8d4b5da866edbec99d9444",
      "fcd18cd0fde844478701d0a7b7522495",
      "b8ee1d1ece634e038566cb1d6b6492b6",
      "0c13e03680834e45be731d9c8789a511",
      "60f1f24cbca74975bfaccba03bd84925",
      "c7a2c4d627344b02bec5d5aa582a0a6e",
      "68aff48cafe84320b4d51970b8eeb3b7",
      "1780a72ea3314adcbc53cfb3769bca71",
      "c7f9f45266964663a99e1dbd4848cb71",
      "9a0131b8d66e4a809f09d683b3d870e7",
      "abbb32759f1a4e1fa2f443f3c0620cbb",
      "29d3ea8de42e4d97b661687db3548bfe",
      "8c77038161a44cb79868eece4c6ec361",
      "9da12f14998a453597d5b3b249ce5588",
      "331d7c5badb14d6db45b9626360224d3",
      "5a48a45d862b439698d23d0076739a59",
      "cdcbc3f796154fc2b3154e0e90c7d280",
      "d2f14e54f03c4510818cf7511a99f474",
      "997a1b9a3c914e0e8e083b52e289f9e4",
      "8c488ad02bf24c0297a61bad6a07565f",
      "5c91f9f9d1f0486cae20c67a56573d2e",
      "550895c2e19346e6944af38990fc0493",
      "cc0f6640a3304c928f9e6e74fd779bc5",
      "5bb6f305e9bc43639a07257d55cf449e",
      "d0fb9913820d44ada2b84ee51a57d736",
      "6976086fc3244b4699aebea604623cae",
      "0f163efcb04d406fb633aa5cb2523c1d",
      "932e2f0e4cbf443aa3fdae6ed2500bb5",
      "c86d3275c1ea497c848eda072ef893c9",
      "cf35a137ed8943f1985ba1c0ce60876a",
      "fd0be146d3b4409fb0a09e3748fbbd7c",
      "6e431ddb41c944d68e338b5e52d21f67",
      "d9840c0b216b426b827620915d1fdd95",
      "ed8b71a88e0d40a2be3f9129f5e3d994",
      "c12e561ed787496585f2fe5f114dbaaa",
      "05dd729f4e5f46b3bc9b72ead0127f95",
      "280005d63db74b919356aed785705c60",
      "3ad1799184cc4e0c822f858710be9d58",
      "6a6ea9eeb28e469e818ed5aed43a14a5",
      "a7838e02851c4aab8bfa8998589f1728",
      "2c5d23f0aec541f6ae9f761bdcf70dcd",
      "f9eb715807f7494dab7a95e3add71153",
      "8afe2dabf0254f559be6f5e5f3889f9c",
      "66479760435247368bc00c9cfbc84848",
      "5cbefc77e60b407a936e5c3a923a24fa",
      "9f4b20f40f904859a4833fa04e1d9bfe",
      "fa3d158b0e4446a0a00af59a4d33100f",
      "a35c9c6c231b41ab90bd58b0fdc2db80",
      "e3f4a97ca7004c23b1fdc05b0d44d641",
      "ab3b641f2a92452d807aa30bb0a1fa32",
      "6c119d7d7351496180ffd298109f4454",
      "52da5464d78a4038a726ef93e2024681",
      "9a61509c4917445c8781299a3e6719ce",
      "c716939bd0094956b8d4d536864d9a0b",
      "fcf7a1e6484a4f12a666492bb3bad7a7",
      "9a0a64bd314c46f6aecab3feb9b92441",
      "45da3de67f1b4a5dba80d9a031e59a95",
      "0d1bbc6e0d244c0da0ab263b72cea0a3",
      "968fea82a03d45bfbf8c7e6eda07a1ca",
      "0184401cbfec429cb39a3e4779cbdb44",
      "38fd9f6fbf544eaaaa79ebece0dcf743",
      "0ebfec25b9194788b27110d087cecae4",
      "4818f3332e14466caf40c00550c6ceb8",
      "dd42b96e0df6494ca80c4052b66257d8",
      "b3895e40b84746a8acd649622824982c",
      "41c7b66e39664c4c81206bbc5255dbb0",
      "fcb4f9618d004bc9bcf659274c061fc2",
      "3d16a3854bce4c93a6b3d714693194d6",
      "b1504b666e184dd8972dd60adc36f5d3",
      "8a49a3db9e51406c8874173466c23090",
      "0649a8d2557840b6925848aa212459f0",
      "505db18d27214fe5ab0fb47de80f9b86",
      "b1a5d1becc1a43a895f967e5cca2759f",
      "7d2419a3ec11497bb4cd7aad0e2d5511",
      "ffecc8c5b90e4a399d6fa872d1b7081e",
      "ef2f4802b85c47438d1e411e0cfefec9",
      "f969ad4598e94415a992c749f80505d9",
      "88f9d4bac6f644d5bbe9263af8c279bf",
      "36b7d0a993694291a4402f51716eae79",
      "76bc57f72c7b4ffa8466877cf8b6c6bb",
      "b44bf66a290c4d16802163705bd54e8b",
      "5b721c91f31e417587b43bf03bef60fa",
      "6d21754b93fe430884255937fe849a23",
      "0b2e065cc5a842a2961cb8ef267f1e36",
      "9a8dfc06aae14fdeb5dc07b9f1aa9ea8",
      "308ab65ee346413a91be4c80427466b3",
      "bd5cae5ad147453d9fa664219836f642",
      "51534a99110c479aba272661b2e14c1c",
      "ddb182ef06174059842fef5de97d1e54",
      "270ab3ddfa334444b1f8a4f1f954ab94"
     ]
    },
    "id": "ee008b45",
    "outputId": "4edc714c-3647-479e-cd61-31e089c52dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (this may require accepting the model license on HF)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1a044d7c1446dc8cee53eea41088cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ee1d1ece634e038566cb1d6b6492b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da12f14998a453597d5b3b249ce5588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fb9913820d44ada2b84ee51a57d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dd729f4e5f46b3bc9b72ead0127f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3d158b0e4446a0a00af59a4d33100f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1bbc6e0d244c0da0ab263b72cea0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1504b666e184dd8972dd60adc36f5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bc57f72c7b4ffa8466877cf8b6c6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "Model dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Base model (change as needed)\n",
    "base_model = 'google/gemma-3-270m-it'\n",
    "checkpoint_dir = os.path.join(OUT_DIR, 'gemma_finetune_checkpoint')\n",
    "\n",
    "print('Loading model (this may require accepting the model license on HF)')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto',\n",
    "    attn_implementation='eager',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "print('Model device:', model.device)\n",
    "print('Model dtype:', model.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a24b42",
   "metadata": {
    "id": "e8a24b42"
   },
   "source": [
    "## 7) Configure SFT and trainer (TRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33a14f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "d8db0889438843768260e6e76013c7e8",
      "af81580ebc534a3dbab98ebe06d2daac",
      "e63d9cc99b3c4190bbf50260ec6011be",
      "d3007ca2ad8949c09438dd952506ee47",
      "cfcf564393be448992fb64d6333e39e0",
      "c1847f3cd04343e69b65f74c14eedf57",
      "92e68de1923a487fbdf2e87fec50f6ed",
      "97111ef254444029ae517fb5a9818bf7",
      "718a777cf4284bf188eee632d0abe5ca",
      "31b1431eaa1749dfbe7c642500e6e27e",
      "8e9043c8e22c426aa25275a5678ed16d",
      "af84cf8cdeba4e0c8706dbb09d4bdffd",
      "bfbfc22ba9a447b58c9747d08edd7e35",
      "f6d61a2964944c789180964452546c9e",
      "1eccb519ec38441d80c1e4b9d96bbb0e",
      "de81417bb0a549d9885581d255972577",
      "e164d482a037455d8e40e3950f39ca76",
      "13e306b623344aa79ecfa0406b0122bf",
      "71b439d078af48dfaae8da80d6a0d3fa",
      "fd6d50b9ef684118a0d7aa6f7aa98cf5",
      "89c50ae402ee407a80d4247c62a7eb4f",
      "2e4d3eb04064437e8598ce2c3156407a",
      "dfb738e0ce5c470bb03b9faa6cfd69e1",
      "70401c4b51164e08ac42cae9a697db3c",
      "5025e23228e540c0b860691f93b7781f",
      "4a11507bfdfe4bf78c21b0ade35d0fec",
      "d957085aece445979fd2140d1a496fe2",
      "fd509b96b9ea46c89620a13c9da95f1d",
      "6094a1e1e6244ee8b788b1fc9f0bdd0e",
      "56eed62d45f746d3b34ab7d3b157f610",
      "857a6668300d4348aa317c60340a2aa6",
      "f3845f757b8c4116b27e5842ca0978d9",
      "e5564315cf0e486ca93052a1dfa8d96f",
      "f5e18ff0f53e4c268213dd3df49c3947",
      "60a0e36c2a5f407c87fcea9f65381a71",
      "60433e7cc1e649279b74065e9493eb9a",
      "3c8970c765d249f1bfc11606925ea012",
      "1f7917c752834ec7b4549757c8eb0e67",
      "ccbf70b8ab8646468a43e077bda9fba3",
      "3f76e2a84f354bb2ab74f48a66bd0165",
      "a62b7cf5c5474d0e8dbc028dfb18fc7d",
      "23cb879aa568415eb8e8de52b0e7fd90",
      "6e6b8e47301247caa7e6457718fce19a",
      "c9fd743fdd4e4b089eb9f3fa410abed0"
     ]
    },
    "id": "e33a14f2",
    "outputId": "fac93708-737a-459e-cf28-7f59a3f8ded8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8db0889438843768260e6e76013c7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af84cf8cdeba4e0c8706dbb09d4bdffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb738e0ce5c470bb03b9faa6cfd69e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e18ff0f53e4c268213dd3df49c3947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "torch_dtype = model.dtype\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=checkpoint_dir,\n",
    "    max_length=512,\n",
    "    packing=False,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_checkpointing=False,\n",
    "    optim='adamw_torch_fused',\n",
    "    logging_steps=1,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True if torch_dtype == torch.float16 else False,\n",
    "    bf16=True if torch_dtype == torch.bfloat16 else False,\n",
    "    lr_scheduler_type='constant',\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard',\n",
    "    dataset_kwargs={\n",
    "        'add_special_tokens': False,\n",
    "        'append_concat_token': True,\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'] if 'test' in dataset else None,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print('Trainer created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08c430",
   "metadata": {
    "id": "6d08c430"
   },
   "source": [
    "## 8) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53fe0e3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "53fe0e3f",
    "outputId": "15d2e906-6a7f-40d9-e1ac-904839943c81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 2, 'pad_token_id': 0}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 02:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.451700</td>\n",
       "      <td>0.439988</td>\n",
       "      <td>0.440077</td>\n",
       "      <td>22332.000000</td>\n",
       "      <td>0.820176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>0.431459</td>\n",
       "      <td>0.427434</td>\n",
       "      <td>44664.000000</td>\n",
       "      <td>0.828661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.435574</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>66996.000000</td>\n",
       "      <td>0.833051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished; model saved to /content/gemma_finetune_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Start training (warning: this will use GPU and can be long)\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "print('Training finished; model saved to', checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f650846",
   "metadata": {
    "id": "8f650846"
   },
   "source": [
    "## 9) Test model inference on test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1509db11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1509db11",
    "outputId": "b6986e81-01e9-40e4-f302-36dc30da19d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Scenario id: 133\n",
      "Distance (m): 15947.9\n",
      "Env: Urban (density=Low)\n",
      "Fresnel clear %: 92.8\n",
      "Weather: Snow, temp C: 35.8\n",
      "Noise floor (dBm): -94.5, RSSI (dBm): -107.7\n",
      "Channel BW (MHz): 80\n",
      "\n",
      "Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\n",
      "Original Answer:\n",
      "5170\n",
      "Generated Answer:\n",
      "5410\n",
      "------------------------------------------------------------\n",
      "Question:\n",
      "Scenario id: 40\n",
      "Distance (m): 12597.4\n",
      "Env: Rural (density=Low)\n",
      "Fresnel clear %: 96.8\n",
      "Weather: Clear, temp C: 20.6\n",
      "Noise floor (dBm): -109.9, RSSI (dBm): -77.2\n",
      "Channel BW (MHz): 80\n",
      "\n",
      "Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\n",
      "Original Answer:\n",
      "5120\n",
      "Generated Answer:\n",
      "5410\n",
      "------------------------------------------------------------\n",
      "Question:\n",
      "Scenario id: 69\n",
      "Distance (m): 16469.2\n",
      "Env: Urban (density=Medium)\n",
      "Fresnel clear %: 80.5\n",
      "Weather: Clear, temp C: 6.1\n",
      "Noise floor (dBm): -89.7, RSSI (dBm): -108.8\n",
      "Channel BW (MHz): 40\n",
      "\n",
      "Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\n",
      "Original Answer:\n",
      "5555\n",
      "Generated Answer:\n",
      "5000\n",
      "------------------------------------------------------------\n",
      "Question:\n",
      "Scenario id: 80\n",
      "Distance (m): 15086.2\n",
      "Env: Urban (density=Low)\n",
      "Fresnel clear %: 62.0\n",
      "Weather: Rain, temp C: 39.3\n",
      "Noise floor (dBm): -94.3, RSSI (dBm): -112.2\n",
      "Channel BW (MHz): 160\n",
      "\n",
      "Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\n",
      "Original Answer:\n",
      "5090\n",
      "Generated Answer:\n",
      "5400\n",
      "------------------------------------------------------------\n",
      "Question:\n",
      "Scenario id: 117\n",
      "Distance (m): 5812.9\n",
      "Env: Urban (density=High)\n",
      "Fresnel clear %: 37.1\n",
      "Weather: Snow, temp C: 6.4\n",
      "Noise floor (dBm): -83.3, RSSI (dBm): -101.7\n",
      "Channel BW (MHz): 80\n",
      "\n",
      "Question: Based on the scenario above, provide the best channel in MHz as a single integer (no explanation).\n",
      "Original Answer:\n",
      "5585\n",
      "Generated Answer:\n",
      "5800\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "if 'test' in dataset:\n",
    "    for i in range(min(5, len(dataset['test']))):\n",
    "        sample = dataset['test'][i]\n",
    "        prompt = pipe.tokenizer.apply_chat_template(sample['messages'][:1], tokenize=False, add_generation_prompt=True)\n",
    "        outputs = pipe(prompt, max_new_tokens=64, disable_compile=True)\n",
    "        print('Question:')\n",
    "        print(sample['messages'][0]['content'])\n",
    "        print('Original Answer:')\n",
    "        print(sample['messages'][1]['content'])\n",
    "        print('Generated Answer:')\n",
    "        print(outputs[0]['generated_text'][len(prompt):].strip())\n",
    "        print('-'*60)\n",
    "else:\n",
    "    print('No test split available to run inference on.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5dbb75",
   "metadata": {
    "id": "3a5dbb75"
   },
   "source": [
    "## 10) Save artifacts and simple loader example\n",
    "\n",
    "Demonstrates saving the generated CSV, the zipped archive, and how you could reload them for offline use. The trainer already saved model checkpoints to `checkpoint_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e6c94d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71e6c94d",
    "outputId": "5c659c85-a1ca-4856-ea82-d47dcb808fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded rows: 200\n",
      "Index(['scenario_id', 'device_a_coordinates', 'device_b_coordinates',\n",
      "       'link_distance_m', 'noise_dbm', 'noise_floor_dbm', 'rssi_dbm', 'snr_db',\n",
      "       'tx_power_dbm', 'channel_bandwidth_mhz'],\n",
      "      dtype='object')\n",
      "Notebook completed. Increase N_SAMPLES and epochs for full training runs.\n"
     ]
    }
   ],
   "source": [
    "# Example: load CSV back\n",
    "reloaded = pd.read_csv(CSV_PATH)\n",
    "print('Reloaded rows:', len(reloaded))\n",
    "print(reloaded.columns[:10])\n",
    "\n",
    "# Example: load a saved model (path: checkpoint_dir)\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint_dir)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n",
    "\n",
    "print('Notebook completed. Increase N_SAMPLES and epochs for full training runs.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}